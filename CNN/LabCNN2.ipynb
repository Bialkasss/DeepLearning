{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKreaeQ7vTQ_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Task\n",
        "Try to solve mnist task using MLP. How many weights are needed, how does the size of an image affect the number of weights?"
      ],
      "metadata": {
        "id": "1V4o7asovmJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "oCAHLcoWwNHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XsfZV_x1wWHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NdRb0mQ9wXcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
        "    'oxford_flowers102',\n",
        "    split=['train[:80%]', 'train[80%:]', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "def preprocess(image, label):\n",
        "  image = tf.image.resize(image, (128, 128))  # Resize images\n",
        "  image = tf.cast(image, tf.float32) / 255.0  # Normalize pixel values\n",
        "  label = tf.one_hot(label, depth=102)  # One-hot encode labels\n",
        "  return image, label\n",
        "\n",
        "tfds.show_examples(ds_train, ds_info)\n",
        "\n",
        "ds_train = ds_train.map(preprocess).cache().shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "ds_val = ds_val.map(preprocess).cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.map(preprocess).cache().batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "AsxPUApEwhJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "Try to predict type of a flower from an image using cnn. You can directly use ds_train, ds_val in a fit function"
      ],
      "metadata": {
        "id": "umAD8nar6rED"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mPd67B6K6yrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you probably noticed it's not so easy. We can enhance the process by using a CNN pretrained on a set of general images. Of course, it cannot be used directly, but the whole feature extraction part can be copied and then maybe slightly adjusted."
      ],
      "metadata": {
        "id": "Q4uS_E_h6zhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
        "    'oxford_flowers102',\n",
        "    split=['train[:80%]', 'train[80%:]', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "# Preprocess the images\n",
        "def preprocess(image, label):\n",
        "  image = tf.image.resize(image, (224, 224))\n",
        "  image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "  return image, label\n",
        "\n",
        "ds_train = ds_train.map(preprocess).cache().shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "ds_val = ds_val.map(preprocess).cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.map(preprocess).cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "ggubPd3J7J9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "The model is quite big, but it's already trained so we froze the weights to not change them during the training phase. After the training is finished the weights can be unfrozen and the training can be repeated to adjust them even better. Now we have only the convolutional part, add the missing part to perform a classification, and compare the results with a model built from scratch."
      ],
      "metadata": {
        "id": "CG-90LjP8dj8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tb58mcho-V5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qRxcE8K9-Vsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image segmentation is an image-to-image task where the output is a binary image with the same shape as the input showing the location of a given object e.g. roads, humans, or signs.\n",
        "\n",
        "A U-net architecture is a popular model used in this task. It allows us to capture not only local patterns and map them to the output. It's presented in a picture below. Of course, it's just an example and the number of layers or number of neurons do not have to be copied one to one."
      ],
      "metadata": {
        "id": "rUf22djG-WWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20220614121231/Group14.jpg\">\n",
        "\n",
        "https://www.geeksforgeeks.org/u-net-architecture-explained/"
      ],
      "metadata": {
        "id": "qdP4PmnA-cDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "Download a retina blood vessel dataset https://www.kaggle.com/datasets/abdallahwagih/retina-blood-vessel create and train an U-net. You can use transfer learning, but it's not a must"
      ],
      "metadata": {
        "id": "P3VLLhAKA-Z2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NvYFqBBB-d0v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}